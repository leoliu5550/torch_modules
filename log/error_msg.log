2024-01-12 20:03:34 [test][DEBUG] [main/<module>] - 9  : {'efficientnet': {'_name': 'efficientnet', '_pymodule': <module 'backbone.efficientnet' from '/Users/leoliu/Documents/project/Rmodules/backbone/efficientnet.py'>}}
2024-01-12 20:21:12 [test][DEBUG] [test_efficient/<module>] - 11  : 
{'efficientnet': {'_name': 'efficientnet', '_pymodule': <module 'backbone.efficientnet' from '/Users/leoliu/Documents/project/Rmodules/backbone/efficientnet.py'>}}
2024-01-12 20:22:44 [test][DEBUG] [test_efficient/<module>] - 11  : 
{'efficientnet': {'_name': 'efficientnet', '_pymodule': <module 'backbone.efficientnet' from '/Users/leoliu/Documents/project/Rmodules/backbone/efficientnet.py'>}}
2024-01-12 20:27:23 [test][DEBUG] [test_efficient/<module>] - 11  : 
{'efficientnet': {'_name': 'efficientnet', '_pymodule': <module 'backbone.efficientnet' from '/Users/leoliu/Documents/project/Rmodules/backbone/efficientnet.py'>}}
2024-01-12 20:27:34 [test][DEBUG] [test_efficient/<module>] - 11  : 
{'efficientnet': {'_name': 'efficientnet', '_pymodule': <module 'backbone.efficientnet' from '/Users/leoliu/Documents/project/Rmodules/backbone/efficientnet.py'>}}
2024-01-12 20:28:09 [test][DEBUG] [test_efficient/<module>] - 13  : 
{'_name': 'efficientnet', '_pymodule': <module 'backbone.efficientnet' from '/Users/leoliu/Documents/project/Rmodules/backbone/efficientnet.py'>}
2024-01-12 20:28:35 [test][DEBUG] [test_efficient/<module>] - 11  : 
{'efficientnet': {'_name': 'efficientnet', '_pymodule': <module 'backbone.efficientnet' from '/Users/leoliu/Documents/project/Rmodules/backbone/efficientnet.py'>}}
2024-01-12 20:28:35 [test][DEBUG] [test_efficient/<module>] - 13  : 
{'_name': 'efficientnet', '_pymodule': <module 'backbone.efficientnet' from '/Users/leoliu/Documents/project/Rmodules/backbone/efficientnet.py'>}
2024-01-12 20:28:47 [test][DEBUG] [test_efficient/<module>] - 11  : 
{'efficientnet': {'_name': 'efficientnet', '_pymodule': <module 'backbone.efficientnet' from '/Users/leoliu/Documents/project/Rmodules/backbone/efficientnet.py'>}}
2024-01-12 20:28:47 [test][DEBUG] [test_efficient/<module>] - 13  : 
{'_name': 'efficientnet', '_pymodule': <module 'backbone.efficientnet' from '/Users/leoliu/Documents/project/Rmodules/backbone/efficientnet.py'>}
2024-01-12 20:29:18 [test][DEBUG] [test_efficient/<module>] - 11  : 
{'efficientnet': {'_name': 'efficientnet', '_pymodule': <module 'backbone.efficientnet' from '/Users/leoliu/Documents/project/Rmodules/backbone/efficientnet.py'>}}
2024-01-12 20:29:23 [test][DEBUG] [test_efficient/<module>] - 11  : 
{'efficientnet': {'_name': 'efficientnet', '_pymodule': <module 'backbone.efficientnet' from '/Users/leoliu/Documents/project/Rmodules/backbone/efficientnet.py'>}}
2024-01-12 20:29:23 [test][DEBUG] [test_efficient/<module>] - 13  : 
<module 'backbone.efficientnet' from '/Users/leoliu/Documents/project/Rmodules/backbone/efficientnet.py'>
2024-01-12 20:29:45 [test][DEBUG] [test_efficient/<module>] - 11  : 
{'efficientnet': {'_name': 'efficientnet', '_pymodule': <module 'backbone.efficientnet' from '/Users/leoliu/Documents/project/Rmodules/backbone/efficientnet.py'>}}
2024-01-12 20:29:45 [test][DEBUG] [test_efficient/<module>] - 13  : 
<module 'backbone.efficientnet' from '/Users/leoliu/Documents/project/Rmodules/backbone/efficientnet.py'>
2024-01-12 21:05:09 [test][DEBUG] [test_efficient/<module>] - 17  : 
efficientnet(
  (bs3): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(inplace=True)
    )
    (1): Sequential(
      (0): FusedMBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.01, mode=row)
      )
      (1): FusedMBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015000000000000003, mode=row)
      )
      (2): FusedMBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02, mode=row)
      )
      (3): FusedMBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.025, mode=row)
      )
    )
    (2): Sequential(
      (0): FusedMBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030000000000000006, mode=row)
      )
      (1): FusedMBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035, mode=row)
      )
      (2): FusedMBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04, mode=row)
      )
      (3): FusedMBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.045, mode=row)
      )
    )
  )
  (bs4): Sequential(
    (0): Sequential(
      (0): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05, mode=row)
      )
      (1): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05500000000000001, mode=row)
      )
      (2): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06000000000000001, mode=row)
      )
      (3): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.065, mode=row)
      )
      (4): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07, mode=row)
      )
      (5): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.075, mode=row)
      )
    )
    (1): Sequential(
      (0): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08, mode=row)
      )
      (1): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.085, mode=row)
      )
    )
  )
  (bs5): Sequential(
    (0): Sequential(
      (0): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=960, bias=False)
            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.125, mode=row)
      )
      (1): MBConv(
        (block): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)
            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(inplace=True)
          )
          (2): SqueezeExcitation(
            (avgpool): AdaptiveAvgPool2d(output_size=1)
            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(inplace=True)
            (scale_activation): Sigmoid()
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13, mode=row)
      )
    )
    (1): Conv2dNormActivation(
      (0): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(inplace=True)
    )
  )
  (input_proj): ModuleList(
    (0): CNNBlock(
      (conv): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leakyrelu): LeakyReLU(negative_slope=0.1)
    )
    (1): CNNBlock(
      (conv): Conv2d(160, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leakyrelu): LeakyReLU(negative_slope=0.1)
    )
    (2): CNNBlock(
      (conv): Conv2d(1280, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leakyrelu): LeakyReLU(negative_slope=0.1)
    )
  )
)
2024-01-12 21:05:11 [test][DEBUG] [test_efficient/<module>] - 20  : 
{'feat1': tensor([[[[ 1.0991e+01, -3.2626e-01,  1.2862e+00,  ..., -4.5325e-01,
           -2.2183e-01,  1.3912e+00],
          [-1.3863e+00,  2.3477e+01,  3.7216e+00,  ...,  2.4968e+00,
           -1.6292e-01,  2.7927e+00],
          [-3.5009e-01,  1.3662e+00, -1.2526e-02,  ..., -1.0750e-01,
            2.2178e+00,  2.5501e+00],
          ...,
          [ 4.3891e+00,  5.5472e+00,  1.8102e+00,  ..., -2.2696e-02,
           -2.2509e-02, -2.7868e-02],
          [ 9.5807e+00,  1.3423e+01, -1.0610e-01,  ..., -1.6090e-02,
           -2.1188e-02, -2.8008e-02],
          [ 9.2112e-01,  6.5392e+00,  2.6550e+00,  ..., -2.2968e-02,
           -3.1657e-02, -2.5860e-02]],

         [[-1.1798e+00,  9.2956e+00,  1.9446e+00,  ..., -2.3810e-01,
            1.2114e+00,  7.0148e+00],
          [ 7.3934e+00,  2.1027e+00,  2.1441e+01,  ...,  4.2241e+00,
            3.6268e+00,  8.9927e-01],
          [-1.2374e+00,  1.1810e+01, -2.4358e-01,  ...,  2.4466e+00,
            3.4975e+00,  3.1045e+00],
          ...,
          [-5.0951e-02,  6.0088e+00,  5.9101e-01,  ..., -2.1166e-02,
           -3.2090e-02, -3.8271e-02],
          [ 4.7361e-01,  3.7776e+00,  5.3822e+00,  ..., -3.1977e-02,
           -3.9770e-02, -5.0696e-02],
          [-2.1041e-01,  2.3746e+00,  7.5262e+00,  ..., -1.9486e-04,
           -8.0439e-03, -8.6581e-03]],

         [[-8.2600e-01, -8.3681e-01, -1.4522e+00,  ..., -8.3821e-01,
           -5.9093e-01,  9.8398e-02],
          [-3.7329e-01, -2.7125e-02,  5.0459e+00,  ..., -1.1250e-01,
            1.4323e+00,  7.2931e-01],
          [-3.8666e-01, -5.6974e-01, -4.3740e-01,  ...,  2.1832e+00,
           -1.2597e-01,  8.1192e+00],
          ...,
          [-4.7648e-01, -5.1246e-01, -1.8552e-01,  ...,  1.8976e-01,
            2.2125e-01,  8.0364e-03],
          [-3.3085e-01, -2.7481e-01,  1.2446e+00,  ...,  1.7175e-01,
            1.9131e-01, -1.3786e-04],
          [-3.2761e-01,  5.3842e-01, -1.7609e-01,  ..., -1.3295e-02,
           -1.0378e-02, -3.3152e-03]],

         ...,

         [[ 2.5025e+00,  6.7511e+00, -5.5845e-01,  ..., -3.3584e-01,
            1.0910e+00,  1.9700e+00],
          [ 4.1404e-01,  2.2788e+01,  8.6380e+00,  ...,  1.1505e+00,
            4.3373e-01, -2.2959e-01],
          [-9.2518e-01, -2.4264e-01, -9.1077e-02,  ..., -2.8115e-01,
           -1.1998e+00, -3.9606e-01],
          ...,
          [-6.5168e-02,  2.5326e-01, -7.8847e-02,  ...,  1.3679e-01,
            1.2814e-01, -1.5213e-02],
          [-4.2904e-01,  6.1828e+00,  5.5822e+00,  ..., -2.4364e-03,
           -4.2700e-04, -3.0687e-02],
          [ 5.7270e-01,  1.0978e+00, -2.0904e-01,  ...,  4.6703e-02,
            8.5533e-02, -1.5424e-02]],

         [[ 1.8329e+00, -6.6942e-01,  1.6002e+01,  ...,  5.9613e+00,
            4.9567e+00,  6.5838e+00],
          [ 7.2298e+00, -1.6325e+00,  7.1721e+00,  ..., -5.3386e-02,
           -2.3831e-01, -1.0908e+00],
          [ 7.2538e+00, -3.3757e-01,  9.9267e+00,  ...,  2.7132e+00,
           -8.6632e-01,  3.5328e+00],
          ...,
          [-3.3325e-01, -5.8178e-01,  6.4683e+00,  ..., -5.2316e-03,
            1.8315e-03,  8.4596e-02],
          [-3.0758e-01, -2.0518e-01,  2.8632e+00,  ...,  2.1742e-01,
            1.8998e-01,  2.2329e-01],
          [-4.8312e-01, -1.0609e-01,  5.1189e+00,  ..., -4.3052e-03,
            2.8988e-02,  1.3130e-02]],

         [[-1.5591e+00, -3.2984e+00, -3.5376e-01,  ..., -6.2319e-01,
           -1.5664e+00, -4.4896e-01],
          [-1.1671e+00, -1.3559e+00,  1.1178e+01,  ..., -3.7705e-01,
           -3.6501e-01,  4.4693e-01],
          [ 1.3295e+01,  2.6426e+00,  2.1091e+01,  ...,  1.3481e+00,
           -8.3546e-02,  5.8593e+00],
          ...,
          [-3.0390e-01, -8.9813e-01, -2.2309e-01,  ...,  3.6536e-02,
            1.4663e-01, -1.0917e-02],
          [-1.4347e-01, -1.0636e+00, -4.5813e-01,  ..., -5.7441e-03,
            1.8570e-02, -2.2117e-02],
          [-2.0550e-01, -8.8389e-01, -5.4823e-01,  ..., -7.6922e-03,
            6.1931e-02, -8.7564e-03]]],


        [[[ 6.5646e+00,  5.8137e-01, -3.1610e-01,  ..., -9.3586e-02,
            8.2953e-01,  8.6447e-01],
          [-7.9328e-01,  1.1373e+01,  1.6950e+00,  ...,  3.9753e+00,
            2.2708e+00,  3.6744e+00],
          [-1.7783e-01,  4.1149e+00,  5.1524e+00,  ...,  4.2660e-01,
            2.4224e+00,  3.6592e+00],
          ...,
          [ 3.2735e-01,  4.8675e+00, -2.3394e-01,  ..., -1.7485e-02,
           -1.4479e-02, -1.8102e-02],
          [ 2.4525e+00,  7.5024e+00, -1.1820e-01,  ..., -1.4147e-02,
           -1.3247e-02, -1.8569e-02],
          [-2.4139e-01,  5.0428e+00,  2.8195e+00,  ..., -1.8821e-02,
           -1.8932e-02, -2.3020e-02]],

         [[-3.0746e-01,  1.0413e+01,  7.8496e+00,  ...,  5.8469e-01,
            8.9193e-01,  2.8941e+00],
          [-6.5838e-02,  8.6812e-01,  1.0830e+01,  ..., -2.4331e-01,
           -6.4306e-01,  3.0245e+00],
          [-4.3380e-01,  6.2197e+00, -3.0772e-01,  ..., -1.8274e-02,
           -2.1612e-01, -2.6466e-02],
          ...,
          [-2.7197e-01,  4.8307e+00, -7.2964e-02,  ...,  9.7796e-03,
           -7.7695e-03, -1.9978e-02],
          [-4.3128e-02,  2.4220e+00,  3.9338e+00,  ..., -5.0210e-03,
           -1.0053e-02, -2.5270e-02],
          [-6.3108e-02,  3.3474e+00,  2.5776e+00,  ...,  1.0554e-01,
            5.3254e-02, -7.8158e-03]],

         [[-5.6327e-01, -4.9463e-01, -5.4777e-01,  ..., -4.3932e-01,
           -4.6532e-01, -1.6876e-01],
          [-8.3557e-02, -4.5882e-01,  1.6824e+00,  ...,  5.2129e-01,
           -1.1328e-01,  3.1575e-01],
          [-3.0963e-03, -6.7885e-02, -3.4979e-01,  ...,  1.2042e+00,
           -6.0833e-02,  2.3808e+00],
          ...,
          [-2.3980e-01, -3.6438e-01, -1.7042e-01,  ...,  1.7074e-01,
            1.1333e-01,  5.1428e-02],
          [-1.0223e-01, -2.6934e-01,  4.5855e-01,  ...,  1.3079e-01,
            7.7514e-02,  3.8000e-02],
          [-2.1696e-01, -2.4115e-01, -6.7533e-02,  ..., -7.2009e-03,
           -9.0169e-03, -7.6942e-04]],

         ...,

         [[-1.0355e-01,  9.2984e+00,  3.8514e-02,  ..., -8.9984e-02,
           -5.4788e-02,  2.1399e+00],
          [-1.5385e+00,  9.2439e+00,  7.6196e+00,  ...,  4.3466e+00,
            3.8758e+00,  1.8954e+00],
          [-6.4125e-01, -1.3525e-01, -2.3972e-01,  ..., -3.9013e-01,
           -7.0561e-01, -4.1644e-01],
          ...,
          [-3.9746e-01,  3.3732e+00,  3.5760e-01,  ..., -3.5490e-03,
           -4.8277e-03, -2.4694e-02],
          [-6.2059e-01,  4.1208e+00,  3.4487e+00,  ..., -1.8005e-02,
           -1.6946e-02, -3.4690e-02],
          [-2.9422e-01,  3.2816e+00,  2.5826e+00,  ..., -2.1940e-02,
           -1.7975e-02, -2.5646e-02]],

         [[-1.0112e-01, -3.2454e-01,  9.8569e+00,  ...,  2.9244e-01,
           -3.0841e-01,  1.4144e+00],
          [-3.7629e-02,  9.7453e+00,  5.2566e+00,  ...,  1.4973e+00,
            1.5805e+00,  1.8820e+00],
          [ 1.3357e+00, -1.7200e-01,  5.3496e+00,  ...,  1.2100e-01,
           -7.2506e-02,  3.7587e+00],
          ...,
          [-4.3785e-01,  3.3997e-01, -7.2699e-02,  ...,  7.1752e-02,
            6.5846e-02, -2.5869e-03],
          [-3.3481e-01,  6.1298e-01,  5.7182e-01,  ...,  2.0229e-01,
            1.4204e-01,  3.3040e-02],
          [-1.5934e-01,  2.7435e-01,  2.4113e+00,  ...,  6.1893e-02,
            6.3646e-02, -7.3478e-03]],

         [[ 1.5165e-01, -1.7460e+00, -1.3345e-01,  ..., -7.3727e-03,
           -5.1773e-01, -3.9581e-03],
          [-2.6619e-01, -2.2111e+00, -4.4733e-01,  ..., -1.2397e-01,
           -1.8781e-01,  1.3895e+00],
          [ 1.8558e+01, -2.7181e-02,  6.8716e+00,  ..., -2.9575e-02,
            8.9901e-01,  1.3062e+00],
          ...,
          [ 3.1963e+00, -3.3477e-01, -3.8142e-01,  ...,  1.7730e-01,
            2.1738e-01, -6.2382e-03],
          [ 2.1056e+00, -2.1753e-01, -1.3949e-01,  ..., -3.6464e-04,
            6.3142e-02, -1.4664e-02],
          [ 1.2316e+00, -5.2459e-02, -6.4483e-01,  ...,  4.0999e-02,
            9.5251e-02, -8.3345e-03]]]], grad_fn=<LeakyReluBackward0>), 'feat2': tensor([[[[-7.6407e-03, -1.4517e-01, -5.7070e-01,  ...,  6.3805e-01,
           -3.0518e-01, -1.5844e-02],
          [-6.5173e-01, -1.1659e+00,  2.2636e+00,  ..., -1.6334e-01,
           -2.2453e-01, -4.6143e-01],
          [-1.5804e-01, -2.8880e-01,  3.0049e+00,  ..., -6.1758e-02,
           -2.1170e-01, -9.1502e-02],
          ...,
          [-2.1259e-01,  1.9865e+00,  1.6216e+00,  ...,  1.7547e-01,
            1.2963e-01,  2.6871e-01],
          [-6.7933e-01, -1.5036e-01,  5.5730e-03,  ...,  1.4268e-01,
            9.4316e-02,  1.8829e-01],
          [-5.3048e-02, -7.4731e-02, -7.5882e-01,  ...,  1.6591e-01,
            1.4060e-01,  3.0613e-01]],

         [[ 1.8053e+00,  1.1919e+01,  5.7606e+00,  ..., -5.0938e-02,
           -2.0515e-01, -5.1103e-01],
          [ 1.1418e+00,  2.5835e+00, -7.8172e-01,  ...,  1.6023e+00,
            4.3923e+00, -5.9703e-02],
          [-1.2242e+00, -4.1870e-01, -9.7470e-01,  ..., -6.1111e-01,
            3.8553e+00,  2.9762e+00],
          ...,
          [ 7.9211e-01,  9.2230e-01,  1.8263e+00,  ...,  2.6062e-01,
            1.4947e-01, -7.3276e-04],
          [ 7.1560e-01,  3.0428e+00, -2.1291e-01,  ...,  1.2799e-01,
           -7.8146e-04, -1.4422e-02],
          [ 1.1295e+00,  5.2881e+00,  5.9728e+00,  ...,  1.1816e-01,
            5.1011e-02, -5.8935e-03]],

         [[ 6.2575e-01, -7.1394e-01, -6.9100e-01,  ..., -1.9697e-01,
           -4.6248e-01, -2.0267e-01],
          [-5.5087e-01, -1.4012e+00, -8.2769e-01,  ..., -1.9414e-01,
           -8.6736e-02,  1.2481e+00],
          [-9.2324e-01, -5.2265e-01, -1.2130e+00,  ..., -5.1304e-01,
           -4.6888e-01,  1.3860e+00],
          ...,
          [-2.2254e-02,  3.9506e-01, -4.8015e-01,  ...,  2.3744e-01,
            1.8295e-01,  8.9714e-02],
          [-3.6111e-01, -6.2010e-02, -1.7551e-01,  ...,  1.6546e-01,
            1.2093e-01,  5.5783e-02],
          [ 3.1458e+00, -1.6126e-01,  2.1564e+00,  ..., -4.5881e-03,
           -5.7831e-03, -3.4106e-04]],

         ...,

         [[ 1.0751e+01, -2.6478e-01, -4.1280e-03,  ..., -1.5851e-01,
           -6.2292e-01,  1.3795e-01],
          [ 6.0442e+00,  9.6110e+00,  2.9155e+00,  ...,  3.1264e+00,
           -2.7572e-01,  8.0605e-01],
          [ 2.7709e+00,  9.7196e+00,  8.2543e+00,  ...,  5.1084e+00,
            2.4275e+00,  3.8019e+00],
          ...,
          [-2.3848e-01,  6.7940e+00,  6.5247e+00,  ..., -2.5122e-02,
           -1.7591e-02, -3.7765e-02],
          [ 1.7595e+00,  6.5162e-02,  3.6785e+00,  ..., -2.9725e-02,
           -2.1780e-02, -4.1962e-02],
          [ 2.7542e+00,  5.4656e-02,  4.7530e+00,  ..., -3.1902e-02,
           -2.9832e-02, -3.4547e-02]],

         [[ 3.5352e+00,  4.6696e+00,  8.7713e+00,  ...,  1.0897e+00,
            1.0527e+00, -1.0271e-01],
          [ 2.4992e+00,  1.2056e+01,  5.0930e+00,  ...,  1.5637e+00,
            4.7848e+00,  1.1162e+00],
          [ 2.6189e+00,  9.4177e+00,  1.4517e+01,  ...,  3.5557e+00,
            4.0067e+00,  3.1086e+00],
          ...,
          [ 1.8787e-01,  2.2267e+00,  3.6847e-01,  ..., -2.3927e-02,
           -3.0009e-02, -1.1597e-02],
          [ 3.4062e+00,  4.1391e+00,  2.8333e+00,  ..., -2.8539e-02,
           -3.4671e-02, -1.6920e-02],
          [ 2.0934e+00,  3.0763e+00,  6.0479e-01,  ..., -2.8274e-02,
           -3.4321e-02, -1.9537e-02]],

         [[ 4.2446e+00, -5.8556e-01, -7.2204e-01,  ...,  1.7862e+00,
           -1.0870e-01,  1.4190e+00],
          [-2.9751e-01, -3.9034e-01, -1.0006e+00,  ..., -2.2140e-01,
           -3.2220e-01, -2.3711e-01],
          [ 1.5901e+00, -1.3030e+00, -4.9647e-01,  ...,  3.4023e+00,
            2.5690e+00, -1.0656e-01],
          ...,
          [-1.8928e-01, -3.6319e-01, -1.2525e-01,  ...,  2.7938e-01,
            1.9950e-01, -6.4392e-03],
          [-3.2860e-01, -7.8010e-01, -4.3207e-01,  ...,  2.5451e-01,
            1.9971e-01,  7.1345e-03],
          [-2.3707e-01, -6.2952e-01, -5.1768e-01,  ...,  2.5371e-01,
            2.2584e-01,  9.5002e-02]]],


        [[[-6.3971e-02, -2.3360e-01, -8.2575e-01,  ..., -2.5060e-02,
           -2.3791e-01, -3.9694e-02],
          [-3.3882e-01, -4.3122e-01, -1.4949e-01,  ..., -5.2322e-02,
            3.4248e+00, -2.0648e-01],
          [ 1.0634e+00,  1.7291e+00,  2.8084e+00,  ..., -1.9814e-01,
           -1.9683e-01, -2.1695e-01],
          ...,
          [-8.3151e-02,  2.6460e+00,  2.0033e+00,  ...,  1.0128e-01,
            2.7339e-02,  2.1483e-01],
          [-9.6542e-02,  5.3773e+00,  2.8080e+00,  ...,  1.1090e-01,
            1.0508e-02,  1.6985e-01],
          [-2.0628e-01, -5.2618e-02, -8.4269e-02,  ...,  8.4201e-02,
            1.6410e-02,  2.5155e-01]],

         [[ 1.5580e+00,  5.9541e+00,  3.7848e+00,  ..., -3.4502e-01,
           -4.9646e-01, -3.6424e-01],
          [-1.0988e-01,  4.4892e+00,  6.8075e+00,  ...,  1.4360e+00,
           -3.4885e-01, -3.0698e-01],
          [-7.6166e-01, -6.4563e-01, -3.6414e-01,  ...,  1.0910e+00,
            1.1245e-01, -1.6060e-01],
          ...,
          [-6.2733e-01, -2.0127e-01, -4.1179e-02,  ...,  1.8368e-01,
            1.3538e-01, -7.7706e-03],
          [-2.9712e-01, -1.6557e-01, -1.8753e-02,  ...,  6.3498e-02,
            3.3287e-02, -1.6065e-02],
          [-1.8758e-01,  7.0918e-02, -2.2723e-02,  ..., -7.8032e-03,
           -9.8658e-03, -1.9351e-02]],

         [[ 5.2159e+00, -5.1661e-01, -1.4772e-01,  ..., -3.4108e-01,
           -2.7663e-01, -2.8271e-01],
          [-2.9987e-01, -1.0238e+00, -4.9571e-01,  ..., -1.5007e-01,
           -1.3848e-03, -2.4541e-01],
          [-3.2025e-01, -3.7876e-01, -2.4011e-01,  ..., -2.6961e-01,
           -2.7234e-01,  5.7782e-01],
          ...,
          [-8.9212e-02, -2.9303e-01, -1.7221e-01,  ...,  3.0071e-01,
            3.6554e-01,  1.0844e-01],
          [-4.3692e-01, -3.0216e-01, -1.7131e-01,  ...,  1.8266e-01,
            2.1768e-01,  7.7315e-03],
          [-6.8635e-02, -1.7938e-01, -7.7171e-02,  ...,  2.3889e-02,
            5.1904e-02, -2.4707e-04]],

         ...,

         [[ 8.9210e-01, -1.0423e+00,  3.8984e+00,  ...,  2.1614e+00,
           -8.7585e-02,  1.4805e+00],
          [-2.7443e-01,  8.8846e-01, -2.2221e-02,  ...,  7.4367e-02,
           -7.9096e-02, -7.0230e-02],
          [-3.3761e-01,  4.9452e+00,  2.2635e-01,  ..., -7.1736e-02,
           -1.3686e-01,  2.8910e+00],
          ...,
          [ 1.4239e-01,  1.4476e+00,  2.2776e+00,  ..., -1.6358e-03,
           -6.5766e-03, -2.9633e-02],
          [-4.3360e-01, -2.3312e-01, -4.1765e-01,  ..., -5.0883e-03,
           -1.1515e-02, -3.2883e-02],
          [-7.7681e-02, -2.3294e-02, -9.0225e-02,  ..., -2.5187e-02,
           -2.7708e-02, -3.3773e-02]],

         [[-2.8643e-03,  3.9697e+00,  8.3882e-01,  ...,  6.3259e-01,
            2.1682e+00, -8.5716e-02],
          [ 5.3304e+00,  5.7992e+00,  2.9116e+00,  ...,  3.4919e+00,
            3.0242e+00,  3.9327e+00],
          [ 2.3144e+00,  7.6539e+00,  8.4564e+00,  ...,  3.7088e+00,
            3.6286e+00, -2.5643e-02],
          ...,
          [ 6.0182e-02,  1.2364e+00,  1.7140e+00,  ..., -3.0651e-02,
           -3.2699e-02, -8.0250e-03],
          [ 1.9422e+00,  3.3200e+00,  1.4958e+00,  ..., -3.6632e-02,
           -4.0803e-02, -1.4803e-02],
          [ 2.8765e+00,  2.8529e+00,  2.0780e+00,  ..., -4.0750e-02,
           -4.2833e-02, -2.5300e-02]],

         [[-2.3319e-01, -1.0072e+00, -5.0603e-01,  ...,  3.2398e-01,
           -1.4703e-01, -6.3176e-02],
          [-1.7501e-01, -7.7583e-01, -4.1256e-01,  ..., -7.3946e-02,
            2.1563e+00, -3.0584e-02],
          [-7.7133e-01, -4.4461e-01, -9.3185e-01,  ..., -2.2375e-01,
           -1.5081e-01, -1.5975e-01],
          ...,
          [-1.9093e-01, -2.5026e-02,  1.5435e-01,  ...,  4.3684e-01,
            3.7412e-01, -2.1982e-04],
          [-3.3268e-02, -1.4313e-01, -4.3835e-02,  ...,  3.3207e-01,
            2.8459e-01, -1.6739e-04],
          [-1.1894e-01, -1.1263e-01, -3.4472e-01,  ...,  3.2705e-01,
            2.8591e-01,  9.0178e-02]]]], grad_fn=<LeakyReluBackward0>), 'feat3': tensor([[[[-7.1326e-01,  6.9769e+00,  3.3247e+00,  ...,  3.4532e-01,
            2.9518e+00,  4.3531e-01],
          [-5.9182e-02,  4.4850e+00, -4.1679e-01,  ...,  1.0637e+00,
           -1.0694e-01, -4.2146e-01],
          [ 4.8193e+00, -4.9707e-01, -5.0924e-01,  ...,  8.8610e-01,
            2.0316e+00, -2.5075e-01],
          ...,
          [ 4.3428e-01, -1.7456e-01, -1.7401e-01,  ...,  2.9169e-03,
            5.2268e-02,  7.6430e-02],
          [ 5.4539e+00, -4.6160e-01,  4.6229e-01,  ...,  3.6195e-02,
            9.0770e-02,  7.8929e-02],
          [ 2.2005e+00,  1.7783e-01, -1.5960e-01,  ..., -5.2946e-03,
           -3.3796e-03,  1.7750e-02]],

         [[-5.4639e-01, -5.5766e-01, -6.3933e-02,  ..., -1.6341e-01,
            3.8172e+00,  3.2465e+00],
          [-1.1517e+00, -1.1588e-01,  1.8828e+00,  ...,  6.9286e-01,
           -3.0239e-01,  1.7616e+00],
          [-2.9907e-02,  1.3212e+00,  9.8106e-01,  ..., -2.2667e-01,
           -2.8994e-01, -2.5280e-04],
          ...,
          [ 1.9121e+00,  1.6185e-01,  4.2284e-01,  ...,  2.3901e-01,
            2.1914e-01, -9.3100e-03],
          [-1.7959e-02,  1.2137e+00,  2.0743e+00,  ...,  2.0695e-01,
            2.2085e-01, -1.2647e-02],
          [-1.0050e-01, -4.2462e-01,  3.3914e+00,  ...,  8.7944e-04,
           -1.8262e-03, -2.7164e-02]],

         [[ 5.8570e-01, -3.3811e-01, -2.4302e-01,  ...,  8.5801e-01,
           -1.8967e-01,  4.8850e-01],
          [-6.5002e-01,  3.8335e+00, -5.6624e-01,  ..., -4.3163e-01,
           -1.5774e-01, -1.4655e-01],
          [-3.5753e-01,  2.3547e+00,  3.8288e+00,  ..., -6.5519e-02,
           -2.2989e-01, -2.8566e-01],
          ...,
          [ 1.3887e+00, -5.4726e-01, -1.0277e-02,  ...,  2.8201e-01,
            3.3615e-01,  8.3654e-02],
          [-3.8492e-01, -3.7671e-01, -3.6336e-01,  ...,  3.2666e-01,
            3.7851e-01,  1.0586e-01],
          [-3.1175e-01,  7.0541e-01,  1.3617e-01,  ...,  2.0062e-01,
            2.8097e-01,  4.4635e-02]],

         ...,

         [[ 3.6258e+00, -4.8381e-02,  6.5322e+00,  ...,  3.8731e+00,
            3.7111e+00,  2.4250e+00],
          [ 4.5040e+00,  5.2349e+00,  9.3092e+00,  ..., -1.9429e-01,
           -3.4584e-01, -1.8683e-01],
          [-5.1525e-01, -4.5758e-01,  5.8296e+00,  ..., -2.2823e-01,
           -5.1273e-01, -3.0610e-02],
          ...,
          [-1.8039e-01, -3.4374e-01, -1.0552e-02,  ..., -2.1238e-03,
           -8.2523e-03, -5.9262e-03],
          [-3.4748e-02, -1.5111e-01, -1.3235e-01,  ..., -7.6032e-03,
           -1.0335e-02, -4.6286e-03],
          [-1.7431e-01, -4.1639e-02, -1.4398e-01,  ..., -1.2352e-03,
           -1.3717e-03, -1.8155e-03]],

         [[-2.4889e-01,  2.1685e+00,  3.5637e+00,  ...,  6.3389e+00,
            2.7061e+00, -9.5715e-02],
          [ 7.8813e+00,  2.5269e-01, -5.7859e-01,  ..., -5.8798e-03,
           -3.6624e-02, -3.9052e-01],
          [-1.6243e-02, -1.0134e-01, -9.6728e-01,  ...,  8.5740e-01,
           -2.1917e-01,  2.2682e+00],
          ...,
          [ 1.3613e+00,  1.1445e+00,  8.7003e-01,  ...,  2.1665e-03,
           -4.6555e-03,  1.0593e-01],
          [ 3.1743e-01, -3.6573e-02, -3.7258e-02,  ..., -1.4244e-03,
           -7.0738e-03,  1.0013e-01],
          [-1.6437e-01, -3.6459e-01, -3.5634e-01,  ...,  8.2795e-02,
            4.7588e-02,  5.2384e-02]],

         [[ 7.5635e+00, -3.0899e-01,  3.5878e+00,  ..., -2.3032e-02,
           -1.1558e-01,  3.9846e+00],
          [ 1.0385e+00,  5.0261e+00,  5.1048e+00,  ...,  6.3838e-01,
           -7.3967e-02,  2.1028e+00],
          [ 1.8557e+00,  8.7353e+00,  5.1748e+00,  ..., -5.0687e-02,
            1.6123e+00,  7.0539e-01],
          ...,
          [ 1.3092e+00,  6.4897e-01,  7.1453e-01,  ..., -3.6269e-02,
           -3.1539e-02, -2.4530e-02],
          [ 3.3492e+00,  2.8179e-01, -1.3724e-01,  ..., -3.3889e-02,
           -3.0622e-02, -2.3222e-02],
          [ 3.8211e+00,  2.7406e+00,  1.7773e+00,  ..., -3.3825e-02,
           -3.4548e-02, -2.5459e-02]]],


        [[[-2.7924e-02, -6.6607e-02, -2.3632e-01,  ..., -1.0322e-01,
           -2.0117e-01, -3.7815e-02],
          [ 3.0880e+00, -5.9438e-01, -1.6377e-01,  ...,  7.0664e-01,
            4.4998e-01, -1.8855e-01],
          [ 3.2433e+00, -2.0255e-03, -7.8092e-03,  ..., -7.4540e-03,
            1.5388e+00, -1.6733e-02],
          ...,
          [ 4.1614e-01, -1.4594e-01, -7.5854e-02,  ...,  4.4375e-02,
            1.1441e-01,  1.7693e-01],
          [-7.7692e-02, -1.5155e-01,  9.3247e-02,  ...,  4.9966e-02,
            1.0761e-01,  1.6767e-01],
          [-1.2199e-01, -4.0160e-02, -1.4593e-01,  ..., -1.0287e-03,
            2.4822e-02,  7.9236e-02]],

         [[-2.0003e-01, -4.9529e-01, -4.6093e-01,  ..., -9.1582e-02,
           -3.8679e-02,  5.1763e-01],
          [-6.0623e-01,  4.0713e+00,  1.4490e+00,  ..., -1.0558e-01,
            3.8336e-01,  3.4146e+00],
          [-4.2687e-01, -4.8540e-01, -2.8244e-02,  ..., -1.0546e-01,
           -1.8222e-01,  3.7506e-01],
          ...,
          [-8.3815e-02, -1.5719e-01,  1.7855e+00,  ...,  1.5434e-01,
            1.5413e-01, -1.5320e-02],
          [-1.0313e-02,  7.5830e-01,  1.0543e+00,  ...,  1.1749e-01,
            1.4197e-01, -1.9030e-02],
          [-3.3590e-01,  5.9335e-01,  2.1657e+00,  ..., -3.6417e-03,
           -3.2517e-03, -3.0227e-02]],

         [[ 2.1748e+00,  6.6187e+00, -6.9167e-02,  ..., -9.3886e-02,
           -4.3790e-02,  5.5046e-01],
          [-2.1436e-01, -3.9941e-01,  2.3108e+00,  ..., -2.8261e-01,
           -3.0379e-01,  2.7661e-02],
          [-9.9388e-02, -4.5217e-01,  6.0113e-01,  ..., -1.4801e-01,
           -1.9944e-01, -9.3546e-02],
          ...,
          [-6.1188e-04,  3.7815e-01, -1.8072e-02,  ...,  2.5064e-01,
            3.1878e-01,  9.8187e-03],
          [ 3.4902e-01,  9.8275e-01, -2.3843e-02,  ...,  2.4565e-01,
            3.0055e-01, -2.3922e-04],
          [ 5.5637e-01,  2.2664e+00,  4.1794e-01,  ...,  2.5133e-01,
            3.2526e-01,  6.7914e-03]],

         ...,

         [[-1.1775e-01,  1.6754e+00,  6.5502e+00,  ...,  9.9132e-01,
            1.2914e+00, -1.4434e-01],
          [ 2.5205e+00, -1.2189e-01, -4.9564e-02,  ..., -6.2485e-02,
           -1.4141e-01, -3.8290e-01],
          [-2.0109e-01, -3.8679e-01, -8.5086e-02,  ..., -4.8166e-02,
           -2.4240e-01, -1.2632e-01],
          ...,
          [ 8.2238e-02,  7.6808e-01,  9.1788e-01,  ..., -3.6179e-03,
           -1.1919e-02, -1.1631e-02],
          [ 5.6391e-01,  1.0591e+00, -5.6161e-03,  ..., -6.7901e-03,
           -1.0945e-02, -1.2297e-02],
          [ 7.2239e-01,  6.3000e-01, -3.4115e-02,  ...,  2.5976e-02,
            1.7220e-02,  8.3520e-03]],

         [[-3.9468e-02, -8.7956e-02,  2.6827e+00,  ...,  8.7950e-01,
            1.0917e+00, -4.7409e-02],
          [-4.8098e-01,  4.6893e+00, -4.8590e-01,  ..., -2.4964e-01,
            4.6311e-01, -1.5213e-01],
          [-5.9050e-02, -4.0132e-01, -4.3163e-01,  ..., -2.0431e-01,
           -2.5014e-01, -9.8307e-02],
          ...,
          [ 5.0578e-01,  2.2093e+00, -7.3244e-02,  ...,  4.7994e-02,
            2.3947e-02,  1.0209e-01],
          [ 9.5059e-02, -1.9940e-01, -3.3586e-02,  ...,  1.5897e-02,
           -1.4892e-03,  9.4598e-02],
          [ 4.6309e-01, -1.5487e-01, -1.2859e-01,  ...,  1.3826e-01,
            1.1976e-01,  6.1066e-02]],

         [[ 4.6542e+00,  5.0342e+00,  3.0306e+00,  ...,  7.1756e-01,
            1.6542e+00,  4.5927e-01],
          [-6.4742e-02,  4.5974e+00,  3.4035e+00,  ...,  1.4167e+00,
            2.1243e+00,  1.6653e+00],
          [ 1.9740e+00,  5.8642e+00,  4.6500e+00,  ..., -1.1910e-01,
            1.9410e-02,  7.3422e-01],
          ...,
          [ 1.1915e+00,  1.9969e-01,  1.5391e+00,  ..., -3.8479e-02,
           -3.2898e-02, -2.7873e-02],
          [ 1.6170e+00,  1.0039e+00,  9.9551e-01,  ..., -3.8857e-02,
           -3.2490e-02, -2.6595e-02],
          [-5.3552e-02,  1.4014e+00,  1.1020e+00,  ..., -3.7796e-02,
           -3.7649e-02, -2.7441e-02]]]], grad_fn=<LeakyReluBackward0>)}
